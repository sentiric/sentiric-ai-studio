ENV_FILE_PATH=.env
CONFIG_REPO_PATH=../sentiric-config
CERTIFICATES_REPO_PATH=../sentiric-certificates
ASSETS_REPO_PATH=../sentiric-assets

ENV="development"
LOG_LEVEL="INFO"



# ==============================================================================
# PROJE KİMLİĞİ (MASTER CONFIGURATION)
# ==============================================================================
# Projenin/Şirketin ana adı. Diğer tüm isimlendirmeler buradan türetilir.
PROJECT_NAME="sentiric"
# Projenin kullanacağı üst seviye alan adı (Top-Level Domain).
PROJECT_TLD="cloud"

# discovery-service
DISCOVERY_DATACENTER_NAME="${PROJECT_NAME}-main"
DISCOVERY_DOMAIN="${PROJECT_NAME}.${PROJECT_TLD}"
DISCOVERY_SERVICE_SUBDOMAIN="service"
DISCOVERY_DNS_SEARCH_DOMAIN="${DISCOVERY_SERVICE_SUBDOMAIN}.${DISCOVERY_DOMAIN}"
# Servis keşif yöntemini belirler. Seçenekler: "HTTP" veya "DNS".
DISCOVERY_METHOD="DNS"

# postgres

# --- Database
POSTGRES_IPV4_ADDRESS=10.88.10.1
POSTGRES_DB_PORT=5432
POSTGRES_DB_HOST=postgres

POSTGRES_PROTOCOL=postgres
POSTGRES_DB=sentiric_db
POSTGRES_USER=sentiric
POSTGRES_PASSWORD=sentiric_pass
POSTGRES_DB_PARAMETERS="sslmode=disable"
# --- Database
POSTGRES_URL="postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_DB_HOST}:${POSTGRES_DB_PORT}/${POSTGRES_DB}?sslmode=disable"


# --- Vector
QDRANT_IPV4_ADDRESS=10.88.10.4
QDRANT_HTTP_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_HOST=qdrant

# --- Vector
QDRANT_HTTP_URL="http://${QDRANT_HOST}:${QDRANT_HTTP_PORT}"
QDRANT_GRPC_URL="${QDRANT_HOST}:${QDRANT_GRPC_PORT}"

# Qdrant'ta oluşturulacak koleksiyonların ön eki. Sonuna tenant_id eklenecek.
QDRANT_DB_COLLECTION_PREFIX=sentiric_kb_

# Metinleri vektöre çevirmek için kullanılacak model. İki servisin de aynı modeli kullanması şarttır.
QDRANT_DB_EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# Paylaşılan RAG ayarları
QDRANT_DB_COLLECTION_PREFIX="sentiric_kb_"
QDRANT_DB_EMBEDDING_MODEL_NAME="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"

# Worker'ın ne sıklıkla yeniden indeksleme yapacağı (saniye cinsinden)
KNOWLEDGE_INDEXING_INTERVAL_SECONDS=3600

# stt-whisper-service:

# IP: 10.88.50.3  =>  Port Bloğu: 1503X
STT_WHISPER_SERVICE_IPV4_ADDRESS=10.88.50.3
STT_WHISPER_SERVICE_HTTP_PORT=15030
STT_WHISPER_SERVICE_GRPC_PORT=15031
STT_WHISPER_SERVICE_METRICS_PORT=15032
STT_WHISPER_SERVICE_HOST=stt-whisper-service

# --- Network Ayarları ---
STT_WHISPER_SERVICE_LISTEN_ADDRESS=0.0.0.0
STT_WHISPER_SERVICE_HTTP_PORT=15030
STT_WHISPER_SERVICE_GRPC_PORT=15031
STT_WHISPER_SERVICE_METRICS_PORT=15032

# --- Model Yönetimi ---
STT_WHISPER_SERVICE_MODEL_DIR=/models
STT_WHISPER_SERVICE_MODEL_FILENAME=ggml-large-v3-turbo-q8_0.bin
# VAD Modeli (Otomatik indirilir)
STT_WHISPER_SERVICE_VAD_MODEL=ggml-silero-vad.bin

# --- Motor ve Performans ---
STT_WHISPER_SERVICE_THREADS=4
STT_WHISPER_SERVICE_DEVICE=auto
STT_WHISPER_SERVICE_COMPUTE_TYPE=float16
# YENİ: Dynamic Batching (Aynı anda işlenecek istek sayısı)
STT_WHISPER_SERVICE_PARALLEL_REQUESTS=2

# --- Transkripsiyon Ayarları ---
STT_WHISPER_SERVICE_LANGUAGE=auto
STT_WHISPER_SERVICE_TRANSLATE=false
# YENİ: Konuşmacı Ayrıştırma (Varsayılan Açık)
STT_WHISPER_SERVICE_ENABLE_DIARIZATION=true
STT_WHISPER_SERVICE_ENABLE_VAD=true

# --- Gelişmiş Ayarlar ---
STT_WHISPER_SERVICE_BEAM_SIZE=5
STT_WHISPER_SERVICE_TEMPERATURE=0.0
STT_WHISPER_SERVICE_BEST_OF=5
STT_WHISPER_SERVICE_LOGPROB_THRESHOLD=-1.0
STT_WHISPER_SERVICE_NO_SPEECH_THRESHOLD=0.6
STT_WHISPER_SERVICE_FLASH_ATTN=true
STT_WHISPER_SERVICE_SUPPRESS_NST=false

# --- Loglama ---
STT_WHISPER_SERVICE_LOG_LEVEL=info


# llm-llama-service

# IP: 10.88.60.7  =>  Port Bloğu: 1607X
LLM_LLAMA_SERVICE_IPV4_ADDRESS=10.88.60.7
LLM_LLAMA_SERVICE_HTTP_PORT=16070
LLM_LLAMA_SERVICE_GRPC_PORT=16071
LLM_LLAMA_SERVICE_METRICS_PORT=16072
LLM_LLAMA_SERVICE_HOST=llm-llama-service
LLM_LLAMA_SERVICE_LISTEN_ADDRESS=0.0.0.0

# --- Sistem Ayarları ---
ENV=development
LLM_LLAMA_SERVICE_LOG_LEVEL=info

# --- Network Ayarları ---
LLM_LLAMA_SERVICE_LISTEN_ADDRESS=0.0.0.0
LLM_LLAMA_SERVICE_HTTP_PORT=16070
LLM_LLAMA_SERVICE_GRPC_PORT=16071
LLM_LLAMA_SERVICE_METRICS_PORT=16072

# --- Model Yönetimi ---
LLM_LLAMA_SERVICE_MODEL_DIR=/models

# --- Gemma-3 1B Q4_0 --- 3,5gb usage ( 4 thread ) - ( 2 thread - 2,36gb) [ Hala en iyi ]
LLM_LLAMA_SERVICE_MODEL_ID=ggml-org/gemma-3-1b-it-qat-GGUF
LLM_LLAMA_SERVICE_MODEL_FILENAME=gemma-3-1b-it-qat-Q4_0.gguf          

# # --- Qwen2.5 Coder 1.5B Q8_0 --- 4,3 gb usage ( 4 thread)
# LLM_LLAMA_SERVICE_MODEL_ID=ggml-org/Qwen2.5-Coder-1.5B-Instruct-Q8_0-GGUF
# LLM_LLAMA_SERVICE_MODEL_FILENAME=qwen2.5-coder-1.5b-instruct-q8_0.gguf  

# # --- Gemma-3 4B Q4_0 --- 3,86gb usage ( 1 thread ) (4,86 2 thread) max
# LLM_LLAMA_SERVICE_MODEL_ID=ggml-org/gemma-3-4b-it-GGUF}
# LLM_LLAMA_SERVICE_MODEL_FILENAME=gemma-3-4b-it-Q4_K_M.gguf}


# --- Motor ve Performans Ayarları ---
LLM_LLAMA_SERVICE_GPU_LAYERS=28
LLM_LLAMA_SERVICE_CONTEXT_SIZE=8192
LLM_LLAMA_SERVICE_THREADS=1
LLM_LLAMA_SERVICE_THREADS_BATCH=1
LLM_LLAMA_SERVICE_USE_MMAP=false
LLM_LLAMA_SERVICE_KV_OFFLOAD=true
LLM_LLAMA_SERVICE_NUMA=disabled

# --- YENİ: Advanced Özellikler ---
LLM_LLAMA_SERVICE_ENABLE_BATCHING=false
LLM_LLAMA_SERVICE_MAX_BATCH_SIZE=1
LLM_LLAMA_SERVICE_BATCH_TIMEOUT_MS=10
LLM_LLAMA_SERVICE_ENABLE_WARM_UP=false

# --- Varsayılan Sampling Parametreleri ---
LLM_LLAMA_SERVICE_DEFAULT_MAX_TOKENS=4096
LLM_LLAMA_SERVICE_DEFAULT_TEMPERATURE=0.8
LLM_LLAMA_SERVICE_DEFAULT_TOP_K=40
LLM_LLAMA_SERVICE_DEFAULT_TOP_P=0.95
LLM_LLAMA_SERVICE_DEFAULT_REPEAT_PENALTY=1.1

# --- Güvenlik Ayarları (mTLS için) ---
GRPC_TLS_CA_PATH=/sentiric-certificates/certs/ca.crt
LLM_LLAMA_SERVICE_CERT_PATH=/sentiric-certificates/certs/llm-llama-service-chain.crt
LLM_LLAMA_SERVICE_KEY_PATH=/sentiric-certificates/certs/llm-llama-service.key
NVIDIA_VISIBLE_DEVICES=all


# IP: 10.88.40.3  =>  Port Bloğu: 1403X
TTS_COQUI_SERVICE_IPV4_ADDRESS=10.88.40.3
TTS_COQUI_SERVICE_HTTP_PORT=14030
TTS_COQUI_SERVICE_GRPC_PORT=14031
TTS_COQUI_SERVICE_METRICS_PORT=14032
TTS_COQUI_SERVICE_HOST=tts-coqui-service

TTS_COQUI_SERVICE_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2

# App Settings
APP_NAME=Sentiric XTTS Service
DEBUG=False

# Hardware
# Eğer CPU kullanacaksanız boş bırakın, GPU için "cuda"
DEVICE=cuda 
CUDA_VISIBLE_DEVICES=0

# Model Agreement (1 = Accept)
COQUI_TOS_AGREED=1

# certificates 
TTS_COQUI_SERVICE_CERT_PATH=/sentiric-certificates/certs/tts-coqui-service-chain.crt
TTS_COQUI_SERVICE_KEY_PATH=/sentiric-certificates/certs/tts-coqui-service.key

# TTS_COQUI_SERVICE_MODEL_NAME="tts_models/multilingual/multi-dataset/xtts_v2"
# TTS_COQUI_SERVICE_MODEL_DEVICE="auto"
# TTS_COQUI_SERVICE_DEFAULT_SPEAKER_WAV_PATH="/app/docs/audio/speakers/tr/default_male.wav"





# IP: 10.88.70.3  =>  Port Bloğu: 1703X
KNOWLEDGE_INDEXING_SERVICE_IPV4_ADDRESS=10.88.70.3
KNOWLEDGE_INDEXING_SERVICE_HTTP_PORT=17030
KNOWLEDGE_INDEXING_SERVICE_GRPC_PORT=17031
KNOWLEDGE_INDEXING_SERVICE_METRICS_PORT=17032
KNOWLEDGE_INDEXING_SERVICE_HOST=knowledge-indexing-service

# certificates 
KNOWLEDGE_INDEXING_SERVICE_CERT_PATH=/sentiric-certificates/certs/knowledge-indexing-service-chain.crt
KNOWLEDGE_INDEXING_SERVICE_KEY_PATH=/sentiric-certificates/certs/knowledge-indexing-service.key

# Bu servise özgü ayarlar
# Worker'ın ne sıklıkla yeniden indeksleme yapacağı (saniye cinsinden)
KNOWLEDGE_INDEXING_INTERVAL_SECONDS=3600



# --- RAG Yetenekleri (KATMAN: 70 - 1) ---
# IP: 10.88.70.2  =>  Port Bloğu: 1702X
KNOWLEDGE_QUERY_SERVICE_IPV4_ADDRESS=10.88.70.2
KNOWLEDGE_QUERY_SERVICE_HTTP_PORT=17020
KNOWLEDGE_QUERY_SERVICE_GRPC_PORT=17021
KNOWLEDGE_QUERY_SERVICE_METRICS_PORT=17022
KNOWLEDGE_QUERY_SERVICE_HOST=knowledge-query-service

KNOWLEDGE_QUERY_SERVICE_CERT_PATH=/sentiric-certificates/certs/knowledge-query-service-chain.crt
KNOWLEDGE_QUERY_SERVICE_KEY_PATH=/sentiric-certificates/certs/knowledge-query-service.key

# Bu servise özgü ayarlar
KNOWLEDGE_QUERY_DEFAULT_TOP_K=3


# XTTS v2’nın GPU memory footprint’i yüksek.


# ✅ 1. XTTS’yi kesin GPU düşük moduna alın
# ➡️ XTTS için düşük VRAM ayarlarını ekleyin:
# Bu memory fragmentation’ı çözer.
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64

# ✅ 2. LLaMA Service GPU Kullanımını KIS
LLM_LLAMA_SERVICE_GPU_LAYERS=16


# ✅ 3. Whisper large-v3-turbo yerine medium-small kullanın
STT_WHISPER_SERVICE_MODEL_FILENAME=ggml-medium-q8_0.bin

# Whisper için CPU kullan:
STT_WHISPER_SERVICE_DEVICE=cpu
STT_WHISPER_SERVICE_COMPUTE_TYPE=int8

# ✅ 4. XTTS modelini CPU/GPU hibrit moduna alın (çok işe yarar)
DEVICE=cuda
TTS_ENABLE_HALF_PRECISION=true
TTS_ENABLE_ATTENTION_KV_CPU_OFFLOAD=true

# ✅ 5. XTTS için batch ve streaming parametrelerini düşürün
TTS_MAX_BATCH_SIZE=1
TTS_ENABLE_STREAMING=false
TTS_ENABLE_HALF_PRECISION=true
TTS_ENABLE_ATTENTION_KV_CPU_OFFLOAD=true